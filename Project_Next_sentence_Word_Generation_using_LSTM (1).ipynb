{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Buisness Scenario: Build a model that can learn language pattern from text and genertae new sentences ,predict the next words when some words are provided to it."
      ],
      "metadata": {
        "id": "zZ6Rpqd7cL4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EWEB76mb5ru"
      },
      "outputs": [],
      "source": [
        "\n",
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "id": "2E3iLObAcPew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary libraries\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore')\n",
        "\n",
        "# Preprocess the text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # creates work tokens, number sequences\n",
        "from tensorflow.keras.utils import pad_sequences # padding\n",
        "from keras.preprocessing import sequence\n",
        "# Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense,LSTM,Embedding\n"
      ],
      "metadata": {
        "id": "QKnVLzjGcSfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOad the dataset"
      ],
      "metadata": {
        "id": "MbRAM8J3cd9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Shakespeare_data.csv')\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "e72AVvu_chun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:15]"
      ],
      "metadata": {
        "id": "-_J5vHVKdFSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using Keras Tokenizer here. Few points are discussed below related to fit_on_texts method and texts_to_sequences method: tokenizer.fit_on_texts(texts) : Builds the word index (vocabulary) from your dataset.\n",
        "\n",
        "It looks at the list of texts you give it. It assigns a unique integer index to each unique word. The most frequent word gets index 1, the next most frequent 2, and so on. Index 0 is reserved for padding.\n",
        "\n",
        "Example: texts = [\"The wizard cast a spell\", \"The spell was powerful\"] tokenizer.fit_on_texts(texts) print(tokenizer.word_index) Output: {'the': 1, 'spell': 2, 'wizard': 3, 'cast': 4, 'a': 5, 'was': 6, 'powerful': 7} tokenizer.texts_to_sequences(texts): Converts your texts into sequences of integers based on the word index created by fit_on_texts.\n",
        "\n",
        "Example: sequences = tokenizer.texts_to_sequences([\"The wizard cast a spell\"])\n",
        "print(sequences) Output: [[1, 3, 4, 5, 2]]\n"
      ],
      "metadata": {
        "id": "voNvXTNUiKBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "# Fit on texts - pass the data\n",
        "tokenizer.fit_on_texts(data['PlayerLine'])\n",
        "word_ind = tokenizer.word_index\n",
        "print(word_ind)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9RUZU7WwiX59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {value:key for key,value in word_ind.items()}\n",
        "reverse_word_index"
      ],
      "metadata": {
        "id": "5l3w-C2HiaRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text on sequences"
      ],
      "metadata": {
        "id": "Xd6s7dO8i5uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "vocab_size = len(word_ind) + 1\n",
        "# to reserve for padding"
      ],
      "metadata": {
        "id": "ZIuszEMxiuGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "id": "gTtt-deSi9XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in data['PlayerLine']:   #iterate through each row in the column\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]   #tokenize the line\n",
        "\n",
        "  for i in range(1,len(token_list)):   # for i in range(1,4)\n",
        "    n_gram_sequence = token_list[:i+1]    # token_list[0:2] = 0th index,1st index\n",
        "    # token_list[0:3] = 0th index,1st index,2nd index\n",
        "    # token_list[0:4] = 0th index, 1st index, 2nd index, 3rd index\n",
        "    input_sequences.append(n_gram_sequence) # [[4,5],[4,5,6],[4,5,6,7]]\n",
        "print(input_sequences[:15])"
      ],
      "metadata": {
        "id": "YbDyBxKbgtzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "padding to bring all the ngram tokens to same size. to bring all the setences to same length\n",
        "\n",
        "max([90,89,77])\n",
        "     "
      ],
      "metadata": {
        "id": "Hmbul1FmjIcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_length = 32\n",
        "input_sequences = sequence.pad_sequences(input_sequences,maxlen=max_length,truncating ='post')\n",
        "input_sequences[:15]\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8IWwt0xjMKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate x and y"
      ],
      "metadata": {
        "id": "7pYhwXO8jUIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_sequences[:,:-1]\n",
        "y = input_sequences[:,-1]\n",
        "\n"
      ],
      "metadata": {
        "id": "EweehdZEjSc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x[:10]"
      ],
      "metadata": {
        "id": "gbQ4TF29jXSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "id": "OGIxxITljZLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape\n"
      ],
      "metadata": {
        "id": "F1EQxwunjdyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y.shape\n",
        "     "
      ],
      "metadata": {
        "id": "hwnMqJdcjiUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to use categorical_crossentropy, then convert y into y cateogrical. y_cat = to_categorical(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "PywZJKJcjmC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Model Buidling"
      ],
      "metadata": {
        "id": "Ph27_e6-jper"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_categorical = to_categorical(y,num_classes=vocab_size)# converts integer labels to categorical format                                                          #where total length here represents vocabulary size\n",
        "\n",
        "model = Sequential()\n",
        "# Provide the input as max length indicating total number of sentences\n",
        "model.add(Input(shape=(max_length,)))# input shape\n",
        "# Add the layers\n",
        "model.add(Embedding(input_dim=vocab_size,output_dim=50,trainable=False)) # Embedding layers to represent words\n",
        "model.add(LSTM(16,return_sequences=True,dropout=0.4)) # return sequences will provide the sequences to next LSTM layer\n",
        "model.add(LSTM(8,dropout=0.3)) # LSTM layer for sequential learning\n",
        "# Add output layer # predicts the probabilities for each word in the vocabulary\n",
        "model.add(Dense(vocab_size, activation='softmax')) #dense and softmax layer for next word prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "CUh45sELjfjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "GuqhGUmbjsxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=5)\n"
      ],
      "metadata": {
        "id": "_zsKCVSBju8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = model.fit(x,y_categorical,validation_split=0.2,epochs=10,callbacks=[early_stop], batch_size = 2)\n"
      ],
      "metadata": {
        "id": "8YAwx-tLjxhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "def generate_text(user_text, next_words=50):\n",
        "    for _ in range(next_words):\n",
        "        # preparing our user text ready for the model\n",
        "        token_list = [tokenizer.word_index.get(w, 0) for w in word_tokenize(user_text.lower())]\n",
        "        token_list = sequence.pad_sequences([token_list],maxlen=max_length-1)\n",
        "        # give the proceesed text to model for prediction of next 50words\n",
        "        predicted_probs = model.predict(token_list.reshape(1, max_length-1), verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1) # it gives you the index of next word\n",
        "        output_word = reverse_word_index.get(predicted[0], '') # convert the index into word using index_word\n",
        "        user_text += ' ' + output_word\n",
        "        # user_text = user_text + output_word\n",
        "    return user_text\n"
      ],
      "metadata": {
        "id": "YbRBKrkUj1MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example usage\n",
        "user = \"Find we are \"\n",
        "generated_text = generate_text(user, next_words = 75)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "lpqEPVNcj6xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "jZZPin3qfcXx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1Kyt_zwgaRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inV3SsKqj6oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "BOcBLpicj6k7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}